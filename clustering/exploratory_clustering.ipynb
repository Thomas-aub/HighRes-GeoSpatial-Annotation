{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1bcc6c",
   "metadata": {},
   "source": [
    "# Satellite Boat Clustering Pipeline\n",
    "\n",
    "This notebook automates the extraction, embedding, clustering, and interactive visualization of boats from high-resolution satellite imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b6d2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 16:15:59.405655: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-17 16:15:59.434542: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-17 16:16:00.072610: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/thomas/miniconda3/envs/boat_cluster/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import custom modules from the src directory\n",
    "from src import _0_Chips as chips\n",
    "from src import _1_Embedding as embedding\n",
    "from src import _2_Clustering as clustering\n",
    "from src import _3_Visualization as visualization\n",
    "from src import _4_Interactive_Map_Context as interactive\n",
    "\n",
    "# Global Configuration\n",
    "RAW_DIR = \"./data/raw\"\n",
    "EXTRACTED_DIR = \"./data/extracted\"\n",
    "RESULTS_DIR = \"./results\"\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(EXTRACTED_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Suppress TensorFlow logging for a cleaner output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8a0a0",
   "metadata": {},
   "source": [
    "## Step 0: Data Extraction (Chips)\n",
    "\n",
    "This step processes the raw `.tif` and `.geojson` pairs. It extracts a strict bounding box for each boat and applies **black padding** to create a square `224x224` image, preserving the boat's original aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41f5885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Found metadata cache at ./data/extracted/metadata_cache.csv\n",
      "       Loaded 21595 samples from cache. Skipping extraction.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Ensure your path variables are correctly defined\n",
    "RAW_DIR = \"./data/raw\"\n",
    "EXTRACTED_DIR = \"./data/extracted\"\n",
    "CACHE_PATH = os.path.join(EXTRACTED_DIR, \"metadata_cache.csv\")\n",
    "\n",
    "# --- CRITICAL FIX: Create the directory if it's missing ---\n",
    "if not os.path.exists(EXTRACTED_DIR):\n",
    "    os.makedirs(EXTRACTED_DIR, exist_ok=True)\n",
    "    print(f\"[Info] Created missing directory: {EXTRACTED_DIR}\")\n",
    "\n",
    "tiffs = glob.glob(os.path.join(RAW_DIR, \"*.tif\"))\n",
    "all_meta = []\n",
    "run_extraction = True\n",
    "\n",
    "# --- CACHE LOGIC ---\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    print(f\"[Info] Found metadata cache at {CACHE_PATH}\")\n",
    "    df_metadata = pd.read_csv(CACHE_PATH)\n",
    "    \n",
    "    # Check if .npy files actually exist\n",
    "    if not df_metadata.empty and os.path.exists(df_metadata.iloc[0]['chip_path']):\n",
    "        print(f\"       Loaded {len(df_metadata)} samples from cache. Skipping extraction.\")\n",
    "        run_extraction = False\n",
    "    else:\n",
    "        print(\"       [Warning] Cache exists but .npy files are missing. Re-extracting...\")\n",
    "\n",
    "# --- EXTRACTION ---\n",
    "if run_extraction:\n",
    "    print(f\"--- Starting Extraction to {EXTRACTED_DIR} ---\")\n",
    "    for t in tiffs:\n",
    "        g = t.replace(\".tif\", \".geojson\")\n",
    "        if os.path.exists(g):\n",
    "            print(f\"Processing {os.path.basename(t)}...\")\n",
    "            # Assuming 'chips' is imported from your src._0_Chips\n",
    "            meta = chips.process_single_pair(t, g, EXTRACTED_DIR, (224, 224))\n",
    "            all_meta.extend(meta)\n",
    "\n",
    "    # Save the new cache\n",
    "    df_metadata = pd.DataFrame(all_meta)\n",
    "    df_metadata.to_csv(CACHE_PATH, index=False)\n",
    "    print(f\"Done! {len(df_metadata)} chips extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f9511",
   "metadata": {},
   "source": [
    "## Step 1: Feature Embedding\n",
    "\n",
    "We load the extracted `.npy` chips and pass them through a pre-trained **ResNet50** model. This converts the visual information of each boat into a numerical vector (embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b0e449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing SatDINO (ViT-Base-16) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/boat_cluster/lib/python3.10/site-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Generating SatDINO Embeddings: 100%|██████████| 21595/21595 [01:19<00:00, 271.56img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings successfully generated and saved for 21595 images.\n"
     ]
    }
   ],
   "source": [
    "# Load extracted metadata\n",
    "metadata_path = os.path.join(EXTRACTED_DIR, \"metadata_cache.csv\")\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Generate embeddings using GPU acceleration\n",
    "# Includes a dynamic progress bar\n",
    "df_embeddings = embedding.get_embeddings_batch_SatDINO(df, batch_size=32)\n",
    "\n",
    "# Save as Pickle to preserve the NumPy array objects in the dataframe\n",
    "df_embeddings.to_pickle(os.path.join(EXTRACTED_DIR, \"embeddings.pkl\"))\n",
    "print(f\"Embeddings successfully generated and saved for {len(df_embeddings)} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b673934",
   "metadata": {},
   "source": [
    "## Step 2: Statistical Clustering\n",
    "\n",
    "This step merges the visual embeddings with physical metadata (latitude, longitude, width, height). It reduces the dimensionality using **ACP** and groups the boats into clusters using a **Gaussian Mixture Model (GMM)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cce9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid embeddings: 21595\n"
     ]
    }
   ],
   "source": [
    "df_emb = pd.read_pickle(os.path.join(EXTRACTED_DIR, \"embeddings.pkl\"))\n",
    "df_emb = df_emb.dropna(subset=['img_feature']).reset_index(drop=True)\n",
    "print(f\"Valid embeddings: {len(df_emb)}\")\n",
    "\n",
    "df_clustered, X_pca = clustering.run_clustering(df_emb, n_clusters=4)\n",
    "df_clustered = df_clustered.reset_index(drop=True)\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "df_clustered.to_csv(os.path.join(RESULTS_DIR, \"clustering_results.csv\"), index=False)\n",
    "np.save(os.path.join(RESULTS_DIR, \"X_pca.npy\"), X_pca)\n",
    "print(f\"Saved {len(df_clustered)} rows, X_pca shape: {X_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201fd4e",
   "metadata": {},
   "source": [
    "## Step 3: Dimensionality Reduction for Visualization\n",
    "\n",
    "To visualize the high-dimensional clusters on a 2D map, we compute **t-SNE** coordinates. These coordinates are injected back into the final CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13303aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Shape: (21595, 50)\n",
      "Loading data for t-SNE...\n",
      "yooo\n",
      "Computing t-SNE (this might take a minute)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1965054 into shape (21595,91)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_pca\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Compute t-SNE and update the CSV with 'tsne_1' and 'tsne_2' columns\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_and_save_tsne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCSV_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPCA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPNG_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/thomas/HighRes-GeoSpatial-Annotation/clustering/src/_3_Visualization.py:33\u001b[0m, in \u001b[0;36mcompute_and_save_tsne\u001b[0;34m(csv_path, pca_path, png_path)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing t-SNE (this might take a minute)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, perplexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m X_2d \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Ajout des coordonnées au DataFrame\u001b[39;00m\n\u001b[1;32m     36\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsne_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m X_2d[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/boat_cluster/lib/python3.10/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/boat_cluster/lib/python3.10/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/boat_cluster/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1144\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \n\u001b[1;32m   1125\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;124;03m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m-> 1144\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/miniconda3/envs/boat_cluster/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:985\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[t-SNE] Indexed \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m samples in \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124ms...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    980\u001b[0m             n_samples, duration\n\u001b[1;32m    981\u001b[0m         )\n\u001b[1;32m    982\u001b[0m     )\n\u001b[1;32m    984\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 985\u001b[0m distances_nn \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m duration \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/miniconda3/envs/boat_cluster/lib/python3.10/site-packages/sklearn/neighbors/_base.py:1030\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors_graph\u001b[0;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     A_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n_queries \u001b[38;5;241m*\u001b[39m n_neighbors)\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1030\u001b[0m     A_data, A_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m     A_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(A_data)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/boat_cluster/lib/python3.10/site-packages/sklearn/neighbors/_base.py:958\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    956\u001b[0m dup_gr_nbrs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mall(sample_mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    957\u001b[0m sample_mask[:, \u001b[38;5;241m0\u001b[39m][dup_gr_nbrs] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 958\u001b[0m neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneigh_ind\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_queries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n\u001b[1;32m    961\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    962\u001b[0m         neigh_dist[sample_mask], (n_queries, n_neighbors \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    963\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/boat_cluster/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:324\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, shape, order, newshape, copy)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m'\u001b[39m, shape, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/boat_cluster/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1965054 into shape (21595,91)"
     ]
    }
   ],
   "source": [
    "CSV_PATH = os.path.join(RESULTS_DIR, \"clustering_results.csv\")\n",
    "PCA_PATH = os.path.join(RESULTS_DIR, \"X_pca.npy\")\n",
    "PNG_PATH = os.path.join(RESULTS_DIR, \"tsne_static.png\")\n",
    "\n",
    "X_pca = np.load(PCA_PATH)\n",
    "print(f\"PCA Shape: {X_pca.shape}\")\n",
    "\n",
    "# Compute t-SNE and update the CSV with 'tsne_1' and 'tsne_2' columns\n",
    "visualization.compute_and_save_tsne(CSV_PATH, PCA_PATH, PNG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b7950",
   "metadata": {},
   "source": [
    "## Step 4: Interactive Exploration\n",
    "\n",
    "The final step launches an interactive window. Clicking on a point in the t-SNE plot opens the specific boat's chip and its global satellite context simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive windows\n",
    "%matplotlib qt \n",
    "\n",
    "# Ensure the paths are correct for the Notebook's root location\n",
    "FINAL_CSV = os.path.join(RESULTS_DIR, \"clustering_results.csv\")\n",
    "# We need to tell the class where the raw TIFFs are\n",
    "interactive.RAW_DATA_DIR = \"./data/raw\" \n",
    "\n",
    "if os.path.exists(FINAL_CSV):\n",
    "    # Initialize the app\n",
    "    # We close any existing plots to prevent event loop conflicts\n",
    "    plt.close('all') \n",
    "    app = interactive.UltimateInteractivePlot(FINAL_CSV)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Error: {FINAL_CSV} not found. Please run the Clustering and Visualization cells first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boat_cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
